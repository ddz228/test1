{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine learning</h1>\n",
    "<li>Creating programs that learn\n",
    "<li>The \"learned\" knowledge is not explicitly contained in the program\n",
    "<li>The program is designed to learn using <b><span style=\"color:darkred\">real world data</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic ideas</h2>\n",
    "<li>The program contains a learning algorithm\n",
    "<li>The program is given data\n",
    "<li>The program applies the learning algorithm to the data and figures stuff out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Terminology</h2>\n",
    "<li><span style=\"color:darkblue\">Feature</span>: A (measurable) property of the learning domain\n",
    "<li><span style=\"color:darkblue\">Feature set</span>: The set of features that are useful for learning in a given domain and a given problem\n",
    "<ul>\n",
    "<li>gender, age, income, other demographic data for predicting credit risk\n",
    "<li>position of pupil, size of nose, presence/absence of dimples in facial data for facial recognition\n",
    "<li>color, intensity of pixels in image data for image recognition\n",
    "<li>moving averages, departures, technical indicators, price in stock price prediction\n",
    "</ul>\n",
    "<li><span style=\"color:darkblue\">Input features</span>: The observable (useful) features in the domain\n",
    "<li><span style=\"color:darkblue\">Output features</span>: A feature that is being learned or predicted\n",
    "<ul>\n",
    "<li>In stock price prediction: moving averages, departures, technical indicators may be input features and the future return the output feature\n",
    "<li>In face recognition: various observable facial features are the input feature and the person (name?) the output feature\n",
    "</ul>\n",
    "<li><span style=\"color:darkblue\">Independent variables</span>: Synonymous with input feature, used in statistical learning\n",
    "<li><span style=\"color:darkblue\">Dependent variables</span>: Synonymous with output feature in prediction problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Types of learning</h2>\n",
    "<li><span style=\"color:darkblue\">Supervised learning</span>: The data set contains paired input and output features and the machine learns how to get the output from the given input. In supervised learning, both input as well as output features are used in learning\n",
    "<li><span style=\"color:darkblue\">Unsupervised learning</span>: The data set contains features and the machine tries to induce concepts or knowledge from this feature set. Typically by organizing the data into \"like\" clusters. In unsupervised learning, only input features are used in learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Examples of machine learning algorithms</h1>\n",
    "<li><span style=\"color:darkblue\">Regression</span>: The machine learns a mathematical relationship between the input and output features. Regression is a supervised learning technique\n",
    "<li><span style=\"color:darkblue\">Classification and regression trees (CART)</span>: The machine learns a set of rules that relate the input and output features. CART is a supervised learning technique\n",
    "<li><span style=\"color:darkblue\">Clustering</span>: Clustering algorithms group the input feature set into \"like\" groups, usually using a distance metric. Clustering algorithms are unsupervised learning techniques\n",
    "<li><span style=\"color:darkblue\">Neural networks</span>: Used for \"deep learning\". Designed to mimic the brain, neural networks are directed, weighted, multi-layered graphs. The first layer is an input layer that corresponds to the input feature set and the final layer is an output layer that corresponds to the output feature set. The graph contains one or more hidden layers and uses an algorithm to compute the weights on the edges to learn the relationship between input and output features. Neural networks are supervised learning techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine learning using Regression</h1>\n",
    "<li>The machine learns a mathematical relationship between the input feature set and output feature values\n",
    "<li>All data must be numerical\n",
    "<li>There is an implied sequence in both independent variable values as well as dependent variable values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Types of regression</h3>\n",
    "<span style=\"color:darkblue\">Linear regression</span>: Learns a mathematical linear relationship between input and output values\n",
    "<li>Linear regression fits a line to the data\n",
    "<li>Single output values\n",
    "<li>Estimates a function of the form:$$ y = { \\alpha + \\beta_1}x_1 + {\\beta_2}x_2 + ..... + {\\beta_n}x_n + {\\epsilon} $$\n",
    "<li>The x values are independent variables\n",
    "<li>The y value is the dependent variable\n",
    "<li>The alpha is a constant intercept term\n",
    "<li>The betas are the feature weights\n",
    "<li>The epsilon is an error term\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear regression example</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardeepjohar/anaconda/envs/py36/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc8af87bb0e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "x=(1,2,3,4,5,6,6,7,9,10)\n",
    "y=(2,4,3,5,6,7,8,9,10,11)\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "plt.scatter(x,y)\n",
    "results = sm.OLS(y,sm.add_constant(x)).fit()\n",
    "x_plot = np.linspace(0,11)\n",
    "plt.plot(x_plot, x_plot*results.params[0] + results.params[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic regression</h2>\n",
    "<li>Predicts a categorical dependent variable value\n",
    "<li>Binomial logistic regression predicts two category values (0 or 1)\n",
    "<li>Typically, the function predicts:\n",
    "<ul> <li>1 if $$ { \\alpha + \\beta_1}x_1 + {\\epsilon} > 0 $$\n",
    "<li>0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification using regression</h1>\n",
    "<li>We will use linear regression to predict binomial categories\n",
    "<li>And examine some of the ways in which we evaluate our ML result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The data</h3>\n",
    "<li>Rocks vs Mines (https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-dat)\n",
    "<li>Though the data is about underwater mines, imagine:\n",
    "<ol>\n",
    "<li>You're looking out at a number of fields that have rock like objects strewn all over the place\n",
    "<li>Some of those objects are actually mines\n",
    "<li>You have special mine detecting equipment \n",
    "<li>The equipment sends sound waves at different frequencies, the waves hit the objects, and report back some sort of measurements\n",
    "<li>Lucky (for you), you have prior sonar data along with whether a rock like object was a rock or a mine \n",
    "<li>You can use this to get your \"machine\" to learn how to identify rocks and mines\n",
    "<li>And then test the results by sending your army across the field - and get an estimate of what it will cost you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read the data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data set 1: Rocks vs. Mines</h3>\n",
    "<li>Independent variables: sonar soundings at different frequencies\n",
    "<li>Dependent variable (target): Rock or Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "df = pd.read_csv(url,header=None)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The data</h4>\n",
    "<li>60 float64 columns. These are the sonar readings and will form our <span style=\"color:blue\">feature set</span>\n",
    "<li>One object column. This will be our target/output/dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Generate a few summary statistics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>See all columns</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=70\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Examine the distribution of the data in column 4</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Quartile 1: from .0067 to .03805\n",
    "<li>Quartile 2: from .03805 to .0625\n",
    "<li>Quartile 3: from .0625 to .100275\n",
    "<li>Quartile 4: from .100275 to .401\n",
    "\n",
    "<h4>Quartile 4 is much larger than the other quartiles. This raises the possibility of outliers</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> A Quantile - Quantile (qq) plot can help identify outliers</h4>\n",
    "<li>y-axis contains values\n",
    "<li>x-axis is the cumulative normal density function plotted as a straight line (-3 to +3)\n",
    "<li>y-axis is the values ordered from lowest to highest\n",
    "<li>the closer the curve is to the line, the more it reflects a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "   \n",
    "stats.probplot(df[4], dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Examine the dependent variable</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[60].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Examine correlations</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "plot.pcolor(df.corr(),cmap='coolwarm') #https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.corr()[0].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Highly correlated items = not good!</h4>\n",
    "<h4>Low correlated items = good </h4>\n",
    "<h4>Correlations with target (dv) = good (high predictive power)</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training a classifier on Rocks vs Mines</h2>\n",
    "<li><span style=\"color:blue\">scikit-learn</span>: A Python machine learning library\n",
    "<li>!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import random\n",
    "#\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#import pylab as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "df = pd.read_csv(url,header=None)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Convert labels R and M to 0 and 1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[60]=np.where(df[60]=='R',0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and testing</h2>\n",
    "<li><span style=\"color:blue\">Training dataset</span>: The model is \"fit\" using a training sample\n",
    "<li><span style=\"color:blue\">Testing dataset</span>: The \"fitted\" model is evaluated on a testing sample\n",
    "<li><span style=\"color:blue\">validation dataset</span>: Sometimes, a dataset is used to \"fine tune\" model parameters after training but before testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We'll use a training and testing dataset\n",
    "<li>And separate out the feature set and target value for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.3)\n",
    "x_train = train.iloc[0:,0:60]\n",
    "y_train = train[60]\n",
    "x_test = test.iloc[0:,0:60]\n",
    "y_test = test[60]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Build the model and fit the training data</h2>\n",
    "<li>The linear regression package is in sklearn's linear_model library\n",
    "<li>We create a linear regression model object\n",
    "<li>And give it our training data to \"fit\" the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluating the model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate mean square errors and R-Square values</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_pred_training = model.predict(x_train)\n",
    "y_pred_testing = model.predict(x_test)\n",
    "training_msq = mean_squared_error(y_pred_training,y_train)\n",
    "testing_msq = mean_squared_error(y_pred_testing,y_test)\n",
    "print(training_msq,testing_msq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Train R-Square:',r2_score(y_train,y_pred_training))\n",
    "print('Test R-Square:',r2_score(y_test,y_pred_testing))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>These are horrible!</h3>\n",
    "<b>But do we really care?</b>\n",
    "<li>Focus on the problem\n",
    "<li>Regression is predicting continuous values between 0 and 1\n",
    "<li>But all we need is a 0 (rock) or a 1 (mine)\n",
    "<li>We may not care about mis-identifying rocks as mines as long as we identify mines correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We want to predict categories: Rocks or Mines\n",
    "<li>But we're actually getting a continuous value\n",
    "<li>Not the same thing. So R-Square and msq probably doesn't mean a whole lot\n",
    "\n",
    "<li>We need to convert the conitnuous values into  categorical 1s and 0s. We can do this by fixing a threshold value between 0 and 1\n",
    "<li>Values greater than the threshold are 1 (Mines). Values less than or equal to the threshold are 0 (Rocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's examine predictions versus actuals for the training and testing datasets</h3>\n",
    "<li>Quick visual on how are model is doing\n",
    "<li>Also a quick picture on how the model is discriminating\n",
    "<li>Since the model is predicting continuous values\n",
    "<ol>\n",
    "<li>we'll create a list containing predicted values for mines\n",
    "<li>and a list containing predicted values for rocks\n",
    "<li>and graph the two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mines = list()\n",
    "rocks = list()\n",
    "actual = np.array(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    \n",
    "    if actual[i]: #mine\n",
    "        mines.append(training_predictions[i])\n",
    "    else:\n",
    "        rocks.append(training_predictions[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_m = pd.DataFrame(mines)\n",
    "df_r = pd.DataFrame(rocks)\n",
    "fig, ax = plt.subplots()\n",
    "a_heights, a_bins = np.histogram(df_m)\n",
    "b_heights, b_bins = np.histogram(df_r, bins=a_bins)\n",
    "width = (a_bins[1] - a_bins[0])/3\n",
    "ax.bar(a_bins[:-1], a_heights, width=width, facecolor='cornflowerblue')\n",
    "ax.bar(b_bins[:-1]+width, b_heights, width=width, facecolor='seagreen')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Repeat for the testing dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mines = list()\n",
    "rocks = list()\n",
    "actual = np.array(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    if actual[i]:\n",
    "        mines.append(testing_predictions[i])\n",
    "    else:\n",
    "        rocks.append(testing_predictions[i])\n",
    "df_m = pd.DataFrame(mines)\n",
    "df_r = pd.DataFrame(rocks)\n",
    "fig, ax = plt.subplots()\n",
    "a_heights, a_bins = np.histogram(df_m)\n",
    "b_heights, b_bins = np.histogram(df_r, bins=a_bins)\n",
    "width = (a_bins[1] - a_bins[0])/3\n",
    "ax.bar(a_bins[:-1], a_heights, width=width, facecolor='cornflowerblue')\n",
    "ax.bar(b_bins[:-1]+width, b_heights, width=width, facecolor='seagreen')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Confusion matrix and the threshold</h3>\n",
    "<li>A confusion matrix evaluates each data point in the testing dataset to see which of the following categories it falls into: \n",
    "<ol>\n",
    "<li><span style=\"color:blue\">true positive</span>: model predicts a mine (1) and it is a mine\n",
    "<li><span style=\"color:blue\">false positive</span>: model predicts a mine but it is a rock (0)\n",
    "<li><span style=\"color:blue\">true negative</span>: model predicts a rock and it is a rock\n",
    "<li><span style=\"color:blue\">false negative</span>: model predicts a rock and it is actually a mine\n",
    "</ol>\n",
    "<li>It then reports the number (or proportion) of cases in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(predicted, actual, threshold):\n",
    "    if len(predicted) != len(actual): return -1\n",
    "    tp = 0.0\n",
    "    fp = 0.0\n",
    "    tn = 0.0\n",
    "    fn = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] > threshold: #labels that are 1.0  (positive examples)\n",
    "            if predicted[i] > threshold:\n",
    "                tp += 1.0 #correctly predicted positive\n",
    "            else:\n",
    "                fn += 1.0 #incorrectly predicted negative\n",
    "        else:              #labels that are 0.0 (negative examples)\n",
    "            if predicted[i] < threshold:\n",
    "                tn += 1.0 #correctly predicted negative\n",
    "            else:\n",
    "                fp += 1.0 #incorrectly predicted positive\n",
    "    rtn = [tp, fp, tn, fn]\n",
    "\n",
    "    return rtn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_predictions = model.predict(x_test)\n",
    "tp,fp,tn,fn = confusion_matrix(testing_predictions,np.array(y_test),0.5)\n",
    "print(tp,fp,tn,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation metrics</h2>\n",
    "Using the results of the confusion matrix, we can calculate a number of metrics that will help evaluate the model\n",
    "<ol>\n",
    "<li><span style=\"color:blue\">true positive rate</span> or <span style=\"color:blue\">sensitivity</span> or <span style=\"color:blue\">recall</span>\n",
    "<li><span style=\"color:blue\">true negative rate</span> or <span style=\"color:blue\">specificity</span>\n",
    "<li><span style=\"color:blue\">false positive rate</span> or <span style=\"color:blue\">fall out</span>\n",
    "<li><span style=\"color:blue\">precision</span> or <span style=\"color:blue\">positive predictive value</span>\n",
    "<li><span style=\"color:blue\">f-score</span>\n",
    "<li><span style=\"color:blue\">accuracy</span>\n",
    "<li><span style=\"color:blue\">misclassification rate</span>\n",
    "\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>True Positive rate/sensitivity/recall</h3>\n",
    "True Positive Rate is the proportion of positive cases that are correctly identified as positive\n",
    "$$ tpr = \\frac{tp}{(tp + fn)} $$\n",
    "Sensitivity is a measure of how good our model is in identifying the positive condition. A value of 1, for example, will mean that every positive value (every mine) was correctly idenfified by the model. \n",
    "<li>Percentage of persons with a disease correctly identified as having that disease\n",
    "<li>Percentage of \"fake news\" items correctly identified as fake news\n",
    "<li>Percentage of consumers who will click on an ad\n",
    "<li>Percentage of customers who will move to a new cell phone carrier at the end of their contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpr = tp/(tp+fn)\n",
    "print(\"Percentage of mines correctly identified as mines:\",tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>True Negative Rate or Specificity</h3>\n",
    "True Negative Rate is the proportion of negative cases that are correctly identified as negative\n",
    "$$ tpr = \\frac{tn}{(tn + fp)} $$\n",
    "<li>Proportion of real news stories that are correctly identified as real news\n",
    "<li>Proportion of healthy people that are correctly identified as healthy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tnr = tn/(tn+fp)\n",
    "print(tnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>false positive rate or \"fall out\"</h3>\n",
    "The false positive rate is the proportion of rocks that have been identified as mines\n",
    "$$ fpr = \\frac{fp}{(fp + tn)} $$\n",
    "\n",
    "<li>Proportion of true news items that are identified as fake news\n",
    "<li>Proportion of consumers who won't use a discount but are identified as target discount users\n",
    "<li>Proportion of rocks that have been identified as mines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr = fp/(fp+tn)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Precision</h3>\n",
    "Precision measures the proportion of cases identified as positive that are actually positive\n",
    "$$ precision = \\frac{tp}{(tp + fp)} $$\n",
    "<li>Proportion of news items that are actually fake from amongst all the news items that are identified as fake\n",
    "<li>Proportion of \"churners\" that are actual churners from amongst all customers identifed as churners\n",
    "<li>Proportion of actual mines amongst all things that are identified as mines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision = tp/(tp+fp)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>f-score</h3>\n",
    "<li>Precision tells us how well our model discriminates amongst cases it identifies as positive. A precision of 1 would mean that if our model says something is positive, it is definitely a positive. \n",
    "<li>Recall tells us how good the model is at finding positives (a recall of 1 would mean it has found all positives). <li>Precision does not tell us how good we are at finding positives while recall does not tell us how good our model is at disciminating\n",
    "<li>The f-score combines the two into a single score\n",
    "$$ F = 2\\frac{precision * recall}{(precision + recall)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = precision*tpr/(precision+tpr)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>accuracy</h3>\n",
    "Accuracy measures how accurately the model classifies things as positive or negative (mines or rocks)\n",
    "$$accuracy = \\frac{tp + tn}{(tp+tn+fp+fn)} $$\n",
    "An accuracy of 1 would mean that our model has classified everything correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>misclassification rate</h3>\n",
    "Misclassifican rate is the inverse of accuracy. What proportion of the cases are misclassified?\n",
    "$$ misclassificationRate = \\frac{fp + fn}{(tp+tn+fp+fn)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misclassification_rate = (fp + fn)/(tp+fp+tn+fn)\n",
    "print(misclassification_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Examining our results</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Precision:\\t\\t%1.2f identified as mines are mines\"%precision)\n",
    "print(\"Recall:\\t\\t\\t%1.2f proportion of actual mines identified\"%tpr)\n",
    "print(\"Specificity:\\t\\t%1.2f proportion of rocks identified as rocks\"%tnr)\n",
    "print(\"False Positive Rate:\\t%1.2f proportion of rocks identified as mines\"%fpr)\n",
    "print(\"f-score:\\t\\t%1.2f tradeoff between precision and recall\"%f)\n",
    "print(\"Accuracy:\\t\\t%1.2f how well the model has classified\"%accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Threshold</h3>\n",
    "<li>Our (regression) model is calculating continuous values between 0 and 1\n",
    "<li>We're using a threshold of 0.5 to decide whether something is a rock or a mine\n",
    "<li>What happens if we use a different threshold value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(threshold):\n",
    "    tp,fp,tn,fn = confusion_matrix(testing_predictions,np.array(y_test),threshold)\n",
    "    precision = tp/(tp+fp)\n",
    "    tpr = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    fpr = fp/(fp+tn)\n",
    "    f = precision*tpr/(precision+tpr)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    print(\"Precision:\\t\\t%1.2f identified as mines are mines\"%precision)\n",
    "    print(\"Recall/Sensitivity:\\t%1.2f proportion of actual mines identified\"%tpr)\n",
    "    print(\"Specificity:\\t\\t%1.2f proportion of rocks identified as rocks\"%tnr)\n",
    "    print(\"False Positive Rate:\\t%1.2f proportion of rocks identified as mines\"%fpr)\n",
    "\n",
    "    print(\"f-score:\\t\\t%1.2f tradeoff between precision and recall\"%f)\n",
    "    print(\"Accuracy:\\t\\t%1.2f how well the model has classified\"%accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Results for .1\")\n",
    "print_results(0.1)\n",
    "print(\"Results for .25\")\n",
    "print_results(0.25)\n",
    "print(\"results for .5\")\n",
    "print_results(0.5)\n",
    "print(\"results for .75\")\n",
    "print_results(0.75)\n",
    "print(\"Results for .9\")\n",
    "print_results(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ROC: Receiver Order Characteristic</h2>\n",
    "<li>An ROC curve shows the performance of a binary classifier as the threshold varies \n",
    "<li>It contrasts\n",
    "<ul>\n",
    "<li>False positive rate (FPR) Fall out/false alarm on the x-axis\n",
    "<li>True Positive rate (TPR) Sensitivity/recall on the y-axis\n",
    "</ul>\n",
    "<li>Each (fpr,tpr) coordinate is calculated for each threshold value and a curve plotted\n",
    "<li>An <span style=\"color:blue\">area under the curve (auc)</span> is calculated. \n",
    "<li>AUC gives us an estimate of how stable our model is to changes in threshold values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Drawing the ROC Curve</h2>\n",
    "<li>sklearn has a function roc_curve that does this for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>In-sample ROC Curve</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "(fpr, tpr, thresholds) = roc_curve(y_train,y_pred_training)\n",
    "area = auc(fpr,tpr)\n",
    "plt.clf() #Clear the current figure\n",
    "plt.plot(fpr,tpr,label=\"In-Sample ROC Curve with area = %1.2f\"%area)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k') #This plots the random (equal probability line)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('In sample ROC rocks versus mines')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Out-sample ROC curve</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(fpr, tpr, thresholds) = roc_curve(y_test,y_pred_testing)\n",
    "area = auc(fpr,tpr)\n",
    "plt.clf() #Clear the current figure\n",
    "plt.plot(fpr,tpr,label=\"Out-Sample ROC Curve with area = %1.2f\"%area)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Out sample ROC rocks versus mines')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Precision vs. Recall</h2>\n",
    "<li>Precision tells us how well we're discriminating within the positively identified  cases\n",
    "<li>Recall tells us what proportion of actual positive cases we've identified as positive\n",
    "<li>Obviously, we'd like both numbers to be close to 1!\n",
    "<li>The precision-recall curve tells us how well we're doing on both factors for different threshold values\n",
    "<li>We can also compute an <span style=\"color:blue\">average precision (AP) metric</span>\n",
    "<ul>\n",
    "<li>AP computes a score at each threshold point\n",
    "<li>Each score is the precision at that point multiplied by the change in recall from the previous threshold point\n",
    "<li>These are then summed up to give a weighted average\n",
    "<li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve,average_precision_score\n",
    "(p,r,thresholds) = precision_recall_curve(y_train,y_pred_training)\n",
    "ap = average_precision_score(y_train,y_pred_training)\n",
    "plt.clf() #Clear the current figure\n",
    "plt.plot(p,r,label=\"In-sample precision recall curve = %1.2f\"%ap)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.title('In sample P-R rocks versus mines')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "(p,r,thresholds) = precision_recall_curve(y_test,y_pred_testing)\n",
    "ap = average_precision_score(y_test,y_pred_testing)\n",
    "\n",
    "plt.clf() #Clear the current figure\n",
    "plt.plot(p,r,label=\"Out-sample precision recall curve = %1.2f\"%ap)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.title('Out sample P-R rocks versus mines')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>So, what threshold should we actually use?</h2>\n",
    "<li>ROC curves and precision-recall curves give you a sense for how good your classifier is and how sensitive it is to changes in threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example: Let's say</h3>\n",
    "<li>Everything classified as a rock needs to be checked with a hand scanner at $200/scan</li> \n",
    "<li>Everything classified as a mine needs to be defused at \\$1000 if it is a real mine or \\$300 if it turns out to be a rock</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp,fp,tn,fn = confusion_matrix(y_pred_testing,np.array(y_test),.1)\n",
    "cost1 = tn * 200 + 1000 * tp + 300 * fp\n",
    "tp,fp,tn,fn = confusion_matrix(y_pred_testing,np.array(y_test),.5)\n",
    "cost2 = tn * 200 + 1000 * tp + 300 * fp\n",
    "tp,fp,tn,fn = confusion_matrix(y_pred_testing,np.array(y_test),.9)\n",
    "cost3 = tn * 200 + 1000 * tp + 300 * fp\n",
    "print(cost1,cost2,cost3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example: Let's say</h3>\n",
    "<li>Everything classified as a rock will be assumed a rock and if wrong, will cost $5000 in injuries</li> \n",
    "<li>Everything classified as a mine will be left as is (no one will walk on it!)</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp,fp,tn,fn = confusion_matrix(testing_predictions,np.array(y_test),.1)\n",
    "cost1 = 5000 * fn\n",
    "tp,fp,tn,fn = confusion_matrix(testing_predictions,np.array(y_test),.5)\n",
    "cost2 = 5000 * fn\n",
    "tp,fp,tn,fn = confusion_matrix(testing_predictions,np.array(y_test),.9)\n",
    "cost3 = 5000 * fn\n",
    "print(cost1,cost2,cost3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bottom line. Depends on factors from your domain</h2>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
